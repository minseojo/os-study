## 김다영

### ch.8
### 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
> 순환 대기 조건은 비선점과 점유하며 대기 조건이 만족되어야 성립됩니다.
> 또 상호배제 조건을 만족하여야 때문에 비선점 조건이 성립되고, 그 반대도 마찬가지 입니다.
> 따라서 네 조건이 완전히 독립적이지 않기 때문에 모든 조건이 충족되어야 데드락이 발생합니다.

### 데드락을 어떻게 예방할 수 있을까요?
> 교착 상태를 예방하기 위해선, 교착 상태의 4가지 필요조건 중 하나 이상 성립하지 않도록 하면 됩니다.
> 가장 실용적인 방법은 모든 자원 유형에 전체적인 순서를 부여해, 각 프로세스가 열거된 순서대로 오름차순으로 자원을 요청하도록 요구해서 순환 대기 조건이 성립하지 않도록 하는 것입니다.


### 왜 현대 OS는 Deadlock을 처리하지 않을까요?
> 대부분의 시스템은 교착 상태가 잘 발생하지 않고, 교착 상태 예방, 회피, 탐지, 복구하는 것은 비용이 많이 들기 때문입니다. 따라서 수작업으로 한번 복구하는 것이 훨씬 효과적입니다.

### ch.9
### 프로세스가 사용 불가능한 메모리 영역에 접근하는 것을 어떻게 막나요?
> 모든 논리 주소는 재배치(기준, base)레지스터와 상한(limit) 레지스터 값을 참조해 확인 작업을 거치기 때문에, 사용 불가능한 메모리 영역에 대한 접근을 막을 수 있습니다.

### 메모리 연속 할당에서 worst-fit은 언제 사용 할까요?
> 남는 공간이 많으므로, 프로세스가 실행 중 추가적으로 메모리를 받아야 하는 경우가 생길 수 있을때 사용하지 않을까,,? 로 짐작..

### TLB를 사용하면 빠른 이유?
> 매번 데이터에 접근하려면 한 번은 PTBR 통해 page table에, 한 번은 페이지 오프셋을 결합해 실제 주소에 접근하는 총 두 번의 메모리 액세스가 필요합니다.
> 반면, TLB에서 원하는 페이지 번호를 찾으면, 해당 프레임 번호를 즉시 알 수 있기 때문에 빠릅니다.

### ch.10
### 가상 메모리가 가능한 이유?
> 논리 주소가 있기 때문입니다.
> +++ 실행 시간 바인딩 시 가상 주소를 물리 주소로 매핑해야 하기 때문에, 불법 프로그램 접근을 막을 수 있다.

### vfork()는 언제 사용하는가?
> vfork() 사용시 부모 프로세스의 주소공간을 사용하게 됩니다. 자식이 부모 공간의 데이터를 수정하면 부모에게도 반영되기 때문에, 해당 시스템콜은 자식이 만들어지자마자 exec() 시스템콜을 호출하는 경우에 사용합니다.

### FIFO 페이지 교체의 단점은?
> 교체된 페이지가 초기화된 뒤 계속해서 자주 사용되는 변수를 포함할 수 있고, 프로세스에 할당되는 페이지 수를 늘렸는데 페이지 폴트율이 증가하는 Belady 모순이 발생할 수 있습니다.

### Thrashing 발생 시, 어떻게 완화할 수 있을까요?
> 멀티 프로그래밍을 정도를 높여 발생했으므로, 멀티 프로그래밍 정도를 낮추어야 CPU 이용률을 높이고 스래싱을 중지시킬 수 있습니다.


## 조민서
### Deadlock(교착 상태)이 무엇인지 설명해 주세요.

레디큐에 프로세스가 있고, 둘 이상의 프로세스가 임계 영역 진입을 무한정 기다리는 상태입니다. 임계 영역에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되어야만 빠져나올 수 있는 상황을 지칭합니다.

즉, **둘 이상의 프로세스가 다른 프로세스가 점유하고 있는 자원을 서로 기다릴 때 무한 대기에 빠지는 상황**
을 말합니다.

### 라이브락에 대해 설명해 주세요.

스레드가 실패한 행동을 계속해서 실패할 때 발생하는 라이브니스 장애입니다. 예를 들어 학생 둘이 복도에서 마주쳤는데 서로 길을 비켜주려고 왼쪽 오른쪽 무한반복 하는 상황입니다.

### 데드락을 특징짓는 4가지 필수조건을 설명해 주세요.

`상호 배제(Mutual Exclusion)` : 한 자원에 대한 여러 프로세스의 동시 접근은 불가능하다. 즉, 하나의 자원을 특정 시기에 하나의 프로세스나 스레드만 소유할 수 있는 형태. (임계영역에는 한개의 프로세스만 들어갈 수 있음)

`점유와 대기(Hold and Wait)` : 하나의 자원을 소유하고 다른 프로세스 혹은 스레드의 자원을 요청하는 상태이다. (식사하는 철학자 문제에서 철학자 5명이 모두 왼쪽 포크를 들고 오른쪽 포크를 기다림)

`비선점(Non preemptive)`  : 하나의 프로세스나 스레드에게 주어진 자원은 해당 프로세스나 스레드가 스스로 놓기 전에는 놓게 만들 수 없는 상태. 즉, 다른 프로세스에서 자원을 사용하는 동안 자원을 강제로 가져올 수 없다. (선점 스케줄링, 비선점 스케줄링을 생각해보면 됨)

`순환대기(Circle wait)` :  각 프로세스가 다음 프로세스가 요구하는 자원을 가지고 있는 것을 말한다. 두 개의 프로세스나 스레드의 경우, A -> B, B -> C, C -> A 에게 서로 자원을 요청하고 기다리는 상황 (사이클)

### 교착 상태 해결 방법을 설명해 주세요.

데드락 4가지 조건들 중 하나라도 제거하면 된다. 예방, 회피, 탐지, 복구방법이 있다.

`예방(Prevention)`: **교착상태가 발생하지 않도록 하는 것.**

상호배제, 점유와대기, 비선점, 순환대기중 하나를 제거해야함, 일반적으로 실용적인 순환대기 사이클을없앰

`회피(Avoidance)` : **교착상태를 피하는 것.** 

**Ex) 자원 할당 그래프 알고리즘, 은행원 알고리즘**

`탐지(Detection)` : **교착상태가 발생하면 탐지 하는 것.**

- **각 유형의 자원이 한 개씩 있는 경우** (대기 그래프 사이클 여부, 사이클 있으면 데드락)
- **각 유형의 자원을 여러 개 가진 경우** (은행원 알고리즘과 비슷한 방식을 사용해서 가능한 모든 할당 순서를 찾는다.)

`복구(Recovery)`: **데드락 상태 프로세스 중지, 자원 선점**

- **교착 상태 프로세스를 모두 중지**

이 방법은 확실하게 데드락의 사이클을 없애지만, 비용이 큽니다. 왜냐하면, 이들 프로세스가 오랫동안 연산했을 가능성이 있으며 또한 락을 점유한 상태로 공유 데이터를 갱신 중이라면 공유 데이터 무결성을 보장할 수 없습니다.

- **교착 상태가 제거될 때까지 한 프로세스씩 제거**

이 방법은 각 프로세스가 중지될 때 마다 데드락 탐지 알고리즘을 호출해 프로세스들이 아직도 데드락 상태인지 확인해야해서 상당한 오버헤드를 유발합니다.

- **자원 선점**

**`희생자 선택`, `후퇴(rollback)`, `기아`** 세가지 고려

1. **희생자 선택**

희생자를 선택할 때는 비용을 최소화하는 선점순서를 결정해야 합니다. 비용 요인으로는 데드락 프로세스가 점유하고 있는 자원의 수, 데드락 프로세스가 지금까지 실행하는 데 소요한 시간 등이 있습니다.

1. 후퇴(rollback)

가장 단순한 해결안은 완전히 롤백 하는 것으로, 모든 프로세스를 중지시키고 재시작 하는 것입니다.

모든 프로세스를 중지 시키는 것 보다는 저장된 정보를 토대로  데드락을 깨뜨릴 수 있을 정도로만 프로세스를 중지 시키는 것이 효과적입니다.

하지만 롤백은 시스템이 실행하는 모든 프로세스의 상태에 대한 많은 정보를 유지해야 합니다.

1. **기아**

우리는 프로세스가 한정된 시간 동안만 희생자로 선정되도록 보장해야 합니다. 그렇지 않으면 계속 같은 프로세스가 희생자가 되어 기아 상태가 될 수 있습니다. 따라서 희생자를 선택하는 비용에 롤백된 횟수를 참고하게 하면 됩니다.

### 데드락을 예방 할 수 있는 방법을 설명해주세요.

우선 데드락 발생조건은 `상호 배제`, `점유하며 대기`, `비선점`, `순환 대기` 조건이 모두 성립되는 경우로 데드락 예방은 이 4개 중 하나라도 제거하면 됩니다.

`상호 배제`는 하나의 임계 영역에는 하나의 스레드만 들어 가야합니다. 즉, 공유 자원을 쓰기위해선 동기화 해야한다는 의미로, 

상호 배제를 제거하면 공유자원을 모두 같이 써야합니다. 하지만 모든 자원을 공유 할 수 없고 한 예로 뮤택스락은 자원을 동시에 여러 스레드가 공유 할 수 없습니다. 

따라서 상호 배제 조건은 제거 할 수 없습니다.

`점유와 대기`는 하나의 스레드가 최소 하나의 자원을 가지고 다른 스레드의 자원을 얻기 위해 대기해야 합니다.

즉, 점유와 대기 조건을 제거하면 CPU가 한 스레드를 점유하기 전에 모든 자원을 할당시키고, 점유하지 않을 때에는 다른 스레드가 자원을 요구하도록 합니다.

이 방법은 두개의 단점이 있습니다.

1. 자원이 할당되어도 장기간 사용되지 않으면 (바쁜대기) 자원 이용률이 낮다.
2. 인기 있는 자원이 여러개 필요한 스레드는 필요한 자원 하나는 항상 다른 스레드에 할당 되므로 기아가 발생한다.

`비선점`은 이미 할당된 자원을 선점하지 못한다 입니다.

즉, 비선점을 제거하면 이미 할당된 자원을 선점 할 수 있습니다.

즉 A 스레드가 B 스레드에게 자원을 요청하면 B 스레드 자원은 A 스레드에게 방출됩니다. 

이 형태는 데이터베이스 트랜잭션처럼 상태가 쉽게 저장되고 복원될 수 있는 자원에 종종 사용되지만, 데드락이 흔하게 발생하는 뮤텍스락과 세마포 같은 자원에는 일반적으로 적용하기가 쉽지 않습니다.

이 3개의 조건을 제거하기는 일반적으로 실용적이지 않지만 순환 대기를 제거하는 것은 실용적입니다.

`순환 대기`는 두 개 이상의 스레드가 적어도 하나의 자원을 가지고 서로 사이클을 이루며 자원을 요청 합니다. 

즉, 순환 대기를 제거하면 각 스레드에 우선순위를 부여하여(순서), 우선순위 순서대로 자원을 요청하도록 합니다. 

### 데드락 회피 방법인 은행원 알고리즘(Banker Algorithm) 에 대해 설명하세요.

데드락을 처리하기 위한 방법 중 회피에 해당하는 알고리즘입니다.

데드락이 발생할지 예측하여 데드락에 빠질 수 있는 상태를 불안전 상태, 데드락에 빠질 수 없는 상태를 안전 상태로 구분하고, 운영체제는 이러한 안전 상태인 경우에만 요청을 허락하여 자원을 할당해주고, 나머지 요구들은 안전 상태가 될 때까지 계속 거절하는 알고리즘입니다.

즉, 은행원 알고리즘은 `은행은 최소한 한 명에게 대출해줄 수 있는 돈을 가지고 있어야 한다`는 뜻에서 나왔으며, 운영체제가 최소한 하나의 프로세스가 일을 수행할 수 있는 경우에만 요청을 허락하여 시스템의 자원을 할당해주는 것과 같습니다.

### 자원 할당 그래프에서 각 자원 유형마다 인스턴스가 하나만 있는 경우 교착상태를 어떻게 찾나요?

각 자원 유형마다 인스턴스가 하나가 있는 경우 자원 할당 그래프를 변형한 대기 그래프(wait-for graph)를 사용하여 교착 상태를 탐지합니다.

# Chapter 9. 메모리 관리

### 기준레지스터(재배치 레지스터)와 상한레지터가 무엇인가요?

기준 레지스터는 가장 작은 물리 메모리 주소의 값을 저장하고, 재배치 레지스터라고도 불립니다.

상한 레지스터는 주어진 영역의 크기, 프로세스의 메모리 범위를 저장합니다.

예를 들어, 기준레지스터값이 300040이고, 상한레지스터값이 120900이라면 이 프로그램은 300040에서 420940싸지 모든 주소를 접근할 수 있습니다.

### 논리주소(가상 주소)와 물리주소에 대해 설명해 주세요.

### **논리 주소, 가상 주소**

**(Logical Address == Virtual Address)**

논리 주소는 CPU에 의해 프로그램이 실행되고 있을 때 만들어진다. 물리적으로 존재하는 주소가 아니라 개념적으로 존재하는 주소이므로 가상 주소Virtual Address라고도 부른다. 논리 주소/가상 주소는 CPU에 위치한 메모리의 물리적 주소를 가르킨다.

Memory-Management Unit, MMU라는 하드웨어 장치는 논리 주소와 대응되는 물리 주소를 연결한다.

Logical Address Space라는 용어는 프로그램에 의해서 만들어진 모든 논리 주소의 집합이다.

### **물리 주소 (Physical Address)**

물리 주소는 메모리 상의 물리적인 주소를 의미한다.

사용자들은 직접적으로 물리 주소로 접근하지 못하고 대신 대응되는 논리 주소로 접근한다. 프로그램들은 논리 주소를 생성하고 해당 프로그램이 이 논리 주소에서 실행되고 있다고 상정한다. 그러나 프로그램이 실행되기 위해서는 물리 주소가 필요하다. 

그래서 MMU가 가상 주소를 물리 주소를 매핑시킨다.

Physical Address Space라는 용어는 Logical Address Space와 대응되는 물리 주소의 집합이다.

### MMU(메모리 관리 장치)에 대해 설명해 주세요.

**MMU는 CPU코어안에 탑재되어 재배치 레지스터값에 가상주소를 더해 실제 메모리 주소(물리 주소)로 변환해주는 장치**입니다..

### OS는 외부 사용자로부터 커널을 어떻게 보호하나요? 가상 주소, 물리 주소 단어 2개를 이용해서 설명해 주세요.

OS는 가상주소와 물리주소를 구분 해 놓았습니다.

가상주소는 CPU에 의해 프로그램이 실행되고 있을 때 만들어집니다. 물리적으로 존재하는 주소가 아니라 개념적으로 존재하는 주소입니다.

물리 주소는 실제 메모리의 물리적 주소 입니다.

논리 주소/가상 주소는 MMU를 이용해 물리 주소에 매핑됩니다.

외부 사용자는 물리 주소에는 직접 접근하지 못하고, 가상 주소를 통해 물리 주소에 접근하는데 OS는 이때 외부 사용자의 불법 침입을 감지합니다.

### 동적 적재(dynamic loading)에 대해 설명해 주세요.

프로세스가 시작될 때 프로세스 주소 공간 전체를 메모리에 올려놓는 것이 아니라 메모리를 좀 더 효율적으로 사용하기 위해 필요한 함수가 호출될 때 해당 함수만 메모리에 적재하는 방식을 말합니다.

즉, 필요한 시점에만 올리니까 메모리를 더 효율적으로 쓰이는게 가능하다.

## 연속 메모리 할당

### 최초 적합(first-fit), 최적 적합(best-fit), 최악 적합(worst-fit)에 대해 설명해 주세요.

하나의 메모리를 여러 프로세스가 사용하기 위해, 여러 개의 메모리로 분할하는데, 이때 각 분할된 메모리의 크기를 가변적으로 만드는 가변파티션 방법이 있습니다.

이때 최초 적합, 최적 적합, 최악 적합은 가용공간크기를 기준으로 프로세스에게 메모리를 어떤식으로 할당해주는지 정하는 방법입니다.

`최초 적합:` 첫 번째 사용 가능한 가용 공간을 할당한다. 검색은 집합의 시작 또는 지난번 검색이 끝난 곳에서 시작 될 수 있습니다.

`최적 적합:`사용 가능한 공간 정에서 가장 작은 것을 선택한다. 리스트가 크기순으로 정렬 되어 있지 않다면 모든 리스트를 검색 해야 하지만 이 방법은 아주 작은 가용 공간을 만듭니다.

`최악 적합:`가장 큰 가용 공간을 선택한다. 할당해 주고 남은 가용공간은 충분히 커서 다른 프로세스들이 유용하게 사용될 수 있다. 이때 가용공간들이 크기 순으로 정렬되어 있지 않으면 모든 리스트를 다 검색해야 합니다.

모의실험(simulation)을 통해서 연구해 보면 최초 적합과 최적 적합 모두가 시간과 메모리 이용 효율 측면에서 최악 적합보다 좋다는 것이 입증되었다. 

최초 적합이나 최적 적합이나 공간 효율성 측면에서는 어느 것이 항상 더 좋다고 말할 수 없지만 최초 적합이 일반적으로 속도가 더 빠르다.

최초적합과 최적적합 모두 외부단편화 문제가 있습니다.

### 내부 단편화(internal fragmentation)와 외부 단편화(external fragmentaion)에 대해 설명해 주세요.

**내부 단편화**: 1000B 크기의 가용공간에서 990B를 요구하는 프로세스가 있으면 시스템은 10B의 가용공간 만큼 더 큰 부담을 가지게 된다. 

따라서 일반적으로 메모리를 먼저 아주 작은 공간들로 분할하고 프로세스가 요청하면 할당을 항상  분할된 크기의 정수 배로 해주는 것이 보통이다. 이 경우 할당된 공간은 요구된 공간보다 약간 더 클 수 있다. 이들 두 크기 사이의 남는 부분이 내부 단편화다.

**외부 단편화:** 프로세스들이 메모리에 적재되고 제거되는 일이 반복되면, 어떤 가용공간은 아주 작은 공간이 됩니다. 이처럼 유휴공간들을 모두 합치면 충분한 공간이 되지만 그것들이 아주 작은 공간들로 분산되어 있을때 외부 단편화가 발생합니다.

최초 적합, 최적 적합 전략 모두 외부 단편화로 인해 어려움을 겪는데 단편화 크기에 따라 어느 전략을 사용할지 결정 합니다.

외부 단편화를 해결하는 방법으로 압축, 페이징 방법이 있습니다.

`압축:` 모든 메모리 내용을 한군데로 몰고 모든 가용공간을 다른 한군데로 몰아서 큰 블록을 만듭니다. 

압축은 항상 가능한것이 아니고, 프로세스들의 재배치가 실행시간에 동적으로 이루어지는 경우에만 가능합니다. 압축은 보통 비용이 많이 듭니다.

`페이징:`한 프로세스의 논리주소공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용되는 경우 물리메모리를 프로세스에 할당하는 방법입니다. 

페이징 기법은 내부 단편화가 존재합니다.

### 가상 메모리 (Virtual Mememory)

가상 메모리란 실제 메모리 크기와 관계 없이 메모리를 사용할 수 있도록 가상 메모리 주소를 사용하는 것을 뜻한다. 프로세스의 일부분만 메모리에 로드하고 나머지는 보조 기억 장치(가상 메모리 공간)에 로드한다.

- MMU를 통해 논리 주소, 물리 주소를 나누어 사용하여 CPU를 속인다.
- MMU = 가상 주소를 실제 메모리 주소로 변환해주는 장치

**장점**

- 실제 메모리 (RAM) 보다 더 큰 공간을 사용
- 가상의 주소를 사용해 논리적인 연속성을 제공
- 물리 메모리의 주소 공간을 몰라도 됨
- 옛날에는 프로그램이 터지면 os 껐다켜야 했음. 가상화 시키면 터진 프로그램이 가상에 있으므로 안정성 보장

## 페이징

### 페이징 과정을 설명해 주세요.


물리 메모리는 프레임이라 불리는 같은 크기의 블록으로 나누어지고, 가상 메모리는 페이지라 불리는 같은 크기의 블록으로 나누어집니다.

CPU에서 나오는 가상 주소는 페이지 번호와 페이지 오프셋을 가집니다. 

페이지 번호는 페이지 테이블에 접근할 때 사용됩니다. 페이지 오프셋은 참조되는 프레임 안에서의 위치입니다. 

즉, 프레임의 시작주소와 페이지 오프셋이 결합하여 물리 메모리 주소가 됩니다.

### **그럼 프레임 시작주소는 어떻게 알지?**

우선 페이지 오프셋은 변하지 않고,

MMU를 통해 페이지 번호로 페이지 테이블에 접근하여 프레임 번호를 추적하고, 프레임 번호와 페이지 오프셋을 이용해 가상주소를 물리주소로 변환합니다.

**요약하자면**

1. 페이지 번호를 추출하여 페이지 테이블의 인덱스로 이동.
2. 페이지 테이블에서 해당 프레임 번호를 추출.
3. 가상 주소의 페이지 번호를 프레임 번호로 바꾼다

### 페이징 단편화

페이징 기법은 일종의 동적 재배치 이므로 외부 단편화가 발생하지 않습니다. 하지만 내부단편화가 발생합니다. 페이지 할당은 항상 프레임의 정수배로 할당되기 때문입니다. 예를 들어 보통 페이지 크기는 4KB입니다.

### 컴퓨터는 64 bit 주소 공간을 가진 시스템에서 페이지의 크기가 4 KB라면 페이지 테이블은 몇 개를 가지나요?

- 64-12 = 약 2^52개의 항목

### 가상 메모리 페이징 기법은 오버헤드가 발생하나요? 왜 오버헤드? 그렇다면 왜 사용하나요?

운영체제는 사용자 프로세스가 사용자 모드(modebit =1)에서 동작할 때, 모든 논리적 주소가 대응되는 물리적 주소를 알고 있어야 한다. 사용자가 논리적 주소를 인자로 시스템 콜을 발생시켰을 때 그 주소는 올바른 물리적 주소로 대응되어야 하기 때문입니다. 

따라서 **운영체제는 각 프로세스의 페이지 테이블 복사본을 가지고 있기 때문에 페이징은 문맥 교환 시간을 늘리므로 오버헤드가 발생합니다.**

하지만 OS가 프로그램에게 가상메모리 영역을 할당하기 때문에 프로그램이 뻗어도 OS가 해당 프로그램의 주소위치를 알기 때문에 자원을 회수할 수 있어 메모리의 낭비가 없고, 프로그램이 죽어도 OS에 영향이 없습니다.

그리고 프로그램은 메모리에 연속적인 공간으로 있는게 아니라 여러곳에 프레임 단위로 분산되어 있습니다. 즉 페이지 테이블은 그 프로세스가 소유하고 있는 페이지들만 가리키고 있기때문에 사용자 프로세스는 자기의 것이 아닌 메모리에는 접근할 수 없습니다.

그리고 프로세스 전체를 메모리에 올리지 않고 프로세스의 필요한 함수들만 메모리에 적재하고, 필요하지 않은 함수는 디스크에 저장함으로써 사용자 프로그램이 물리 메모리보다 커도 실행이 가능하도록 만듭니다.

그리고 페이징 기법은 내부단편화가 존재하지만, 외부단편화문제는 해결 되었습니다.

### 그럼 페이징 문맥교환 시간을 어떻게 줄이나요?

- 하드웨어 이용 (페이지 테이블 기준 레지스터, TLB-캐시)

### 페이지 테이블 기준 레지스터(Page-Table Base Resister, PTBR)

페이지 테이블을 메인메모리에 저장하고 페이지 테이블 기준 레지스터가 페이지 테이블의 시작 주소을 가르킵니다. 다른 페이지 테이블을 사용하려면 이 레지스터 값만 변화시키면 되기 때문에 문맥교환 시간을 줄일 수 있습니다.

하지만 메인메모리에 저장하기 때문에 페이지 테이블에 접근할 때 1번, 페이지 테이블에서 프레임 번호를 찾아 실제 데이터에 접근할 때 1번 메모리에 총 2번 접근합니다.

그래서 메모리 접근 시간이 증가합니다. 이것은 페이징 성능에 아주 큰 영향을 끼칩니다. 이 문제를 해결하기 위해 TLB를 이용합니다.

### **TLB (Translation Look aside Buffer)**

메모리에 여러번 접근해서 메모리 접근 시간이 더 걸리는 문제를 해결하기 위해, 페이지 테이블을 위한 소형의 하드웨어 캐시가 있습니다.

캐시 실패시 또는 페이징 테이블 변환주소로 메인메모리 물리 주소를 찾을때(메인 메모리에 분할되어 있을 수 있음) 똑같이 메모리에 여러번 접근해야 하지만 , 히트 적중률을 높여 페이지 테이블을 읽는 속도 만큼은 매우 빠르게 한다는 것이 페이지 테이블 캐싱의 원리입니다. 그리고 MMU는 이런 페이지 테이블 캐싱을 위해서 컴퓨터 시스템에 있는 캐시 메모리를 그대로 이용하는 것이 아니고 MMU내에 TLB라고 하는 페이지 테이블만 전용으로 캐싱하는 별도의 캐시 메모리를 두게 됩니다.

- 접근 속도가 매우 빠른 연관 메모리 (associative memory)
- TLB 내의 각 항목(entry)은 키(key)와 값(value)로 구성되며 key는 페이지 번호, value는 페이지 번호에 해당하는 프레임 번호이다.
- 전체적으로 MMU 하드웨어가 주소 변환을 하는 과정을 살펴보자면
1. CPU가 메모리를 참조하기 위해서 그 데이터의 논리 주소를 꺼내게 될 것이다. 
2. 그러면 이 논리 주소 중에서 페이지 번호에 해당하는 부분을 가지고서 페이지 테이블 참조를 할 텐데 이 때는 일단 TLB를 먼저 참조하게 된다. 
3. 그런데 TLB는 페이지 테이블의 일부만 갖고 있기 때문에 인덱스를 바로 참조하는 것이 아니고 내가 가지고 있는 페이지 번호가 TLB안에 있는지를 검색을 해야 한다. 
4. 그리고 검색한 결과 해당 페이지 번호가 있다면 프레임 번호를 얻어내어 물리 주소를 형성하게 되는 것이다. 이렇게 되면 빠른 속도로 프레임 번호를 얻을 수 있다.(TLB hit) 
5. 하지만 원하는 페이지 번호가 없다면 이는 TLB miss라고 하는 것이고 이렇게 되면 어쩔 수 없이 TLB 참조 후에 메모리 안에 저장되어 있던page table도 참조를 해야 한다. 
6. 그래서 이렇게 TLB miss가 나게되면 TLB가 없을 때보다 더 긴 시간이 걸리게 된다. 따라서 이 시스템이 원할하게 잘 동작 하려면 TLB에서 내가 원하는 페이지를 찾을 확률이 매우 높아야만 한다.

### 페이지 테이블 보호

페이지 테이블의 각 엔트리에는 유효/무효(valid, invalid)라는 하나의 비트가 있습니다.

이 비트가 유효로 설정되면 페이지가 프로세스의 합법적인 페이지임을 나타내고, 무효로 설정되면 그 페이지는 가상 주소 공간에 속하지 않았음을 나타냅니다.

예를 들어, 위 그림에서 페이지 1, 2, 3, 4, 5의 가상 주소는 페이지 테이블을 통하여 정상적으로 사상되지만, 페이지 6, 7에서 주소를 매핑 하려고 하면, 무효 비트가 설정되어 있어 트랩(invalif page reference)을 발생 시킵니다.

프로세스가 자신의 모든 주소 범위를 늘 사용하는 경우는 드물고 보통 일부분을 집중적으로 사용합니다. 이런 경우 모든 페이지를 페이지 테이블에 배정하는 것은 낭비 이므로 몇몇 시스템은 페이지 테이블 크기를 나타내는 페이지 테이블 길이 레지스터(Page Table Length Resiter, PTLR)을 제공합니다.

### 공유 페이지에 대해 설명해 주세요.

페이징의 장점은 공통의 코드를 공유할 수 있습니다.

UNIX 및 LINUX에 대한 시스템 콜을 제공하는 똑같은 표준 C 라이브러리를 40개의 프로세스에서 사용하면 똑같은 함수가 메모리 위에 40개 있다.

그러나 재진입 코드인 경우 위 그림처럼 코드를 공유할 수 있다. 표준 C 라이브러리는 물리 메모리에 하나의 사본만 저장하면 되고, 각 사용자 프로세스의 페이지 테이블은 동일한 물리적 사본에 매핑 시킵니다.

따라서 40개의 프로세스여도 40개의 함수가 아니라 1개의 함수만 메모리에 올립니다.

### 페이징 기법과 세그멘테이션 기법을 설명해 주세요.

### 페이징(Paging)기법

**외부 단편화 해결, 내부 단편화 존재**

가상메모리를 같은 크기의 블록으로 나눈 것을 페이지라고 하고 

RAM을 페이지와 같은 크기의 블록으로 나눈 것을 프레임이라고 한다. 

페이징 기법이란 사용하지 않는 프레임을 페이지로 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 방법을 말한다.

페이지와 프레임을 대응시키기 위해 페이지 매핑이 필요해서 페이지 테이블을 만든다. 페이징 기법을 사용하면 연속적이지 않은 공간도 활용할 수 있기 때문에 **외부 단편화 문제를 해결**할 수 있다. 

그러나 페이지 단위를 작게하면 외부 단편화 문제를 해결할 수 있지만 그 대신 **페이지 매핑이** **많아져 효율이 떨어지게 된다**.

### **세그멘테이션(Segmentation)기법**

**내부 단편화 해결, 외부 단편화 존재**

페이징기법에서 가상메모리를 같은 크기의 단위로 분할했지만 세그멘테이션기법에서는 가상메모리를 서로 크기가 다른 논리적 단위의 세그먼트로 분할한 후 메모리를 할당하여 물리 주소에 매핑합니다. 

각 세그먼트는 연속적인 공간에 저장되어 있다. 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아 할당하는 기법이다. 

페이징 기법과 마찬가지로 매핑을 위해 세그먼트 테이블이 필요하다. **프로세스가 필요한 메모리 만큼 할당해주기 때문에 내부단편화는 일어나지 않으나** 여전히 중간에 프로세스가 메모리를 해제하면 생기는 틈, 즉 **외부 단편화 문제는 해결되지 못한다**.

### 메모리 풀(Memory Pool)기법

## 페이지 테이블의 구조

### 64비트 논리 주소 공간을 가진 시스템에서 계층적 페이징(Hierachical Paging) 기법 또는 for-ward-mapped 페이지 테이블이 부적합한 이유를 설명해주세요.

페이징 기법은 모든 페이지 테이블을 메인 메모리에서 연속적으로 할당하지 않기 위해 사용하는 기법 입니다.

64비트 논리 주소 공간을 가진 시스템에서 우선 각 페이지의 크기가 4KB 라고 가정하고, 페이징 테이블을 만들면

2^64 / 2^12 → 64-12 즉 2^52개의 페이지 테이블을 가진다. 2단계 페이징 기법을 이용하면  안쪽 페이지 테이블은 1페이지가 되는데, 여기서는 2^10개의 4B(byte) 짜리 항목을 가진다. 바깥 페이지 테이블은 2^42개의 페이지 테이블을 가지고 2^44 B로 구성된다. 2^42B*4B 

즉 바깥 테이블은 2^44B의 크기를 요구한다.

- 이와 같은 방식으로
    
    3단계 32 10 10 12
    
    4단계 22 10 10 10 12
    
    5단계 12 10 10 10 10 12
    
    6단계 2 10 10 10 10 10 12와 같이 7단계  페이징이 필요하다. 각 논리 주소를 사상하기 위해 너무 많은 메모리 접근을 필요로 하기 때문에 비현실 적이다. 
    
    그래서 64비트 컴퓨터는 가상주소를 해시로 사용하는 해시 페이지 테이블 또는 해시 페이지 테이블과 비슷한 클러스터 페이지 테이블을 사용합니다.
    
    해시테이블과 클러스터 테이블 차이점
    
    **해시 페이지 테이블**의 각 항목이 한 개의 페이지만 가리키는 것에 반해 **클러스터 페이지 테이블**의 각 항목은 여러(예를 들면 16개) 페이지를 가리킵니다.
    
     따라서 한 개의 페이지 테이블 항목이 여러 페이지 프레임에 대한 변환 정보를 지닐 수 있습니다. 클러스터 페이지 테이블은 **성간(**sparse, 메인 메모리에서 stack영역과 heap영역 사이에 비어있는 메모리) 주소 공간에 유용하게 사용됩니다. 
    
    즉 클러스터 페이지 테이블은 메모리 액세스가 비연속적이면서 전 주소 공간으로 넓게 퍼져 나오는 경우에 유용합니다
    
    

**하지만 32비트 라면?**

각 페이지의 크기가 4KB라면 12비트 오프셋과

20비트짜리 페이지 번호로 나뉘는데, 2단계 페이징을 하면 10비트 페이지테이블 10비트짜리 페이지 오프셋으로 나뉜다. 

즉 계층적 페이징 기법은 32비트 시스템을 위한 기법이다.

### **해시 페이지 테이블 (Hashed Page Table)**

- 논리 주소의 페이지 번호를 해시 값으로 사용
- 32비트 이상의 논리 주소 공간을 위한 페이지 테이블 구성방법
- 같은 위치에 해당되는 해시 페이지 테이블의 항목은 연결 리스트 구성 - 페이지 번호, 프레임 번호, 다음 원소 포인터

### **역 페이지 테이블 (Inverted Page Table)**

**물리 메모리의 프레임 번호로 인덱스되는 테이블**

원래 페이지 테이블에서는 프로세스의 논리 주소를 인덱스로 하고 해싱을 해서 실제 메모리의 프레임 주소로 바꿔준다.

이때 논리 주소 공간의 관점에서 보면 실제 프로세스가 사용하지 않는 것들에 대해서도 페이지 테이블 엔트리를 유지하기 때문에 이 공간의 낭비가 생기게 된다.

**주소 변환**

논리주소: 프로세스 ID, 페이지 번호, 오프셋

프로세스 ID와 페이지 번호로 페이지 테이블을 검색 (search)

발견된 항목의 인덱스가 프레임 번호

**역 페이지 테이블의 특징**


## 스와핑

### 모든 프로세스의 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리보다 큰 경우 OS는 어떻게 해결하나요? (스와핑)

프로세스가 실행되려면 메모리에 있어야 하는데, 그래서 프로세스가 스와핑(swapping)을 해야 합니다. 스와핑이란  프로세스의 일부분이 현재 메모리에서 잠깐 다른 저장 공간(HDD나 SSD 등 백업 장치)으로 내보내졌다가 다시 메모리로 돌아올 수 있는 개념입니다.

이렇게 하면 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리보다 큰 경우에도 스와핑을 이용하면  프로세스를 동시에 실행하는 것이 가능합니다 스와핑의 적합한 후보는 유휴(idle) 또는 대부분의 시간을 유휴상태로 보낸 프로세스가 스와핑에 적합한 후보입니다.

스와핑의 적합한 후보는 유휴(idle) 또는 대부분의 시간을 유휴상태로 보낸 프로세스가 스와핑에 적합한 후보입니다.

하지만 (표준스와핑)메모리와 백업저장장치 간에 프로세스전체를 이동하는데 걸리는 시간이 엄청나기 때문에 최신 os에서는 사용하지 않음. → 프로세스를 스와핑 하는게 아니라 페이지를 스와핑함, 이 과정을 페이징 이라고함.

### 프로세스를 스와핑 하는 것과 페이지를 스와핑 하는 것은 무엇이 다른가요?

프로세스를 스와핑 하는것은 PCB 전체 내용을 바꾸지만 페이지는 프로세스의 일부분만 동적으로 재배치 하기때문에 메모리와 백업저장장치간에 프로세스 전체를 이동하는거보다 효율적입니다.

### 모바일에서 스와핑

모바일은 비휘발성 저장장치를 용량이 작은 플래시메모리를 쓴다. 그래서 스와핑을 하게되는 이유중 하나.

안드로이드나 ios는 스와핑을 사용하지 않고, 가용메모리가 부족하면 프로세스를 강제 종료시키는것이 가능합니다. 종료하기전에 응용프로그램 상태를 플래시메모리에 저장하여 나중에 빠르게 재시작 할 수 있게합니다.

# Chapter 10. 가상 메모리

### 요구 페이징(demand paging)에 대해 설명해 주세요.

요구 페이징의 기본 개념은 필요할 때만 페이지를 메모리에 적재하는 것 입니다.

결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 보조저장장치에 있습니다. 

따라서 이 둘을 구별하기 위해서 유효•무효(valid-invalid)비트 기법이 사용될 수 있습니다.

### 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 어떤 일이 발생하나요? (페이지 폴트)

페이지 테이블 항목이 무효로 설정되어 있으므로 페이지 폴트 트랩(page-fault trap)을 발생 시킵니다.

### 페이지 폴트는 무엇인가요?

페이지 폴트란 **프로그램이 자신의 주소 공간에는 존재하지만 메인메모리에 현재 없는 데이터나 코드에 접근 하였을 경우 발생하는 현상입니다.**

### 페이지 폴트를 처리하는 과정을 설명해 주세요.


1. 프로세스에 대한 내부 테이블(internal table)[일반적으로 프로세스 제어 블록 (PCB)과 함께 유지]을 검사해서 그 메모리 참조(reference)가 유효•무효인지를 알아낸다.
2. 만약 무효한 페이지에 대한 참조라면 그 프로세스는 중단된다. 만약 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 그것을 보조저장장치로부터 가져 와야 한다.
3. 빈 공간, 즉 가용 프레임(free frame)을 찾는다(예를 들면, 페이지 프레임 리스트 에서 하나를 가져옴). 빈 프레임이 있다면 바로 할당이 가능하지만 꽉 차있다면 이제 page replacement에 대한 고려를 해야 한다.
4. 보조저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위 해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다. 이제 프로세스는 마치 그 페이지 가 항상 메모리에 있었던 것처럼 해당 페이지에 접근할 수 있다.

**정리하자면**

페이지를 참조하여 CPU가 연산을 하기위해 페이지 테이블에 접근하는데 해당 페이지가 무효 하다면 트랩이 걸려 OS가 CPU 제어를 하게 되고 보조저장장치에서 해당 페이지를 물리적 메모리에 올립니다.

하지만 보조저장장치**에 접근하는 것은 시간적 오버헤드가 무척 크기 때문에 페이지 폴트 비율을 낮추는 것이 중요합니다.**

표준 스와핑을 사용하여 프로세스를 스왑아웃하여 모든 프레임(물리 메모리)을 비우고 다중프로그래밍 정도를 줄 일 수 있지만, 메모리와 스왑공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분 os는 표준 스와핑을 사용하지 않는다.

### 순수 요구 페이징

어떤 페이지가 필요해지기 전에는 결코 그 페이지를 메모리에 적재하지 않는 방법

즉 페이지가 메모리에 올라와 있지않으면 계속 페이지 폴트를 발생시키고 메모리에 적재합니다. 

이는 오버헤드를 아주 많이 발생하지만 극단적인상화에서 함수 코드가 10000줄인데 마지막에 일반적인 페이징에서 페이지 폴트를 시키면 처음부터 다시 시작해야 하므로 페이지를 메모리에 올리면서 함수를 실행하고 페이지 폴트가 일어나면 이전 주소부터 다시 시작합니다.

### 쓰기 시 복사(copy-on-write) 방식에 대해 설명해 주세요.

fork를 하면 부모 프로세스의 페이지들을 실제로 자식 프로세스에 복사해 줌으로써 자식 프로세스의 주소 공간을 구성해 줍니다. 

하지만 대부분의 자식 프로세들은 exec 시스템 콜을 하는데, 이러면 부모로부터 복사해온 페이지들이 다 쓸모 없어집니다. 

그래서 부모의 페이지들을 다 복사해오는 대신 쓰기 시 복사(copy-on-write) 방식을 사용할 수 있습니다.


위 두개의 그림을 보자 자식 프로세스가 시작할 때 부모 페이지를 당분간 함께 사용합니다. 

운영체제는 가용 프레임 리스트에서 프레임을 얻고 이 페이지의 복사본을 만들어서 자식 프로세스의 주소 공간에 사상시킨다. 따라서 자식은 그 개인용으로 따로 만 들어준 페이지에(부모와 공유하는 페이지가 아닌) 수정을 가하게 되는 것이다. 

이렇게 하면 프로세스가 수정을 하는 페이지들에 대해서만 복사본이 생기게 된다. 수정되지 않은 페이지들은 자식과 부모 간에 계속 공유될 수 있는 것이다.

### fork()와 vfork() 차이점을 말해주세요.

초록색 글씨 = fork()

주황색 글씨 = vfork()

fork와 vfork의 주된 차이점은 fork에 의해 생성 된 자식 프로세스가 부모 프로세스와는 별도의 메모리 공간을 가지고 있다는 것입니다.

그러나 **vfork** 시스템 호출로 작성된 자식 프로세스는 부모 프로세스**와 동일한 주소 공간**을 공유합니다.

fork를 사용하여 생성된 자식 프로세스는 부모 프로세스와 동시에 실행됩니다.

반면, vfork를 이용하여 생성된 자식 프로세스는 실행이 완료될 때까지 부모 프로세스의 실행을 일시 중단합니다.

fork는 부모와 자식 프로세스의 메모리 공간이 다른 프로세스에 의해 수행된 별도의 수정이므로 다른 페이지에 영향을 미치지 않습니다. 

반면, vfork는 부모와 자식 프로세스가 메모리 공간이 동일한 프로세스에 의해 수행된 같은 메모리의 주소 수정이므로 다른 페이지에 영향을 미칩니다.

fork는 대안으로 **copy-on-write** 를 사용하여 부모와 자식 프로세스가 페이지를 수정하기 전까지 동일한 주소 공간을 공유하게 합니다. 

반면, vfork는 copy-on-write를 사용하지 않습니다. 그래서 vfork를 통한 자식이 부모 주소 공간의 페이지를 수정하게 되면 변경된 페이지가 재 실행 시 부모 프로세스가 그대로 보입니다. 따라서 vfork를 사용할 때에는 자식이 부모 주소 공간의 페이지를 변경하지 않도록 주의해야 합니다.

- fork:
    
    부모와 자식간의 별도의 독립된 메모리공간
    
    부모와 자식 동시 실행
    
    수정시 별도의 수정으로 다른 페이지에 영향X
    
    copy-on-write사용O
    
- vfork:
    
    부모와 자식간의 같은 메모리 공간
    
    자식 실행시 부모는 블로킹됨(경생상황 방지)
    
    자식 수정시 부모와 같은 메모리주소 수정으로 다른 페이지에 영향O
    
    copy-on-write사용X
    

### 메모리 초과 할당이 일어나는 과정 그리고 해결 방안을 말해주세요.

1. 프로세스가 실행되는 동안 페이지 폴트 발생
2. os는 보조저장장치에 저장된 페이지 위치를 찾지만 물리 메모리에 들어갈 자리가 없음을 인지.
3. 해결 과정
    
    1. 프로세스를 종료하는 방법이 있지만, 시스템의 활용률과 처리율 관점에서 좋은 방법이 아님.
    
    2. 또한 표준 스와핑을 사용하여 프로세스를 스왑아웃하여 모든 프레임(물리 메모리)를 비우고 다중프로그래밍 정도를 줄 일 수 있지만, 메모리와 스왑 공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분 os는 표준 스와핑을 사용하지 않는다.
    
    3 .스와핑(페이징)과 페이지 교체를 결합한다.
    

페이지 교체 알고리즘은 페이지 폴트 발생 비율을 줄이는 것을 목표로 합니다.

## **페이지 교체 알고리즘의 종류**

1. **OPT** - Optimal : 앞으로 가장 오랫동안 사용되지 않을 페이지 교체
2. **FIFO** - First In First Out
3. **LRU** - Least ***Recently*** Used : 가장 오랫동안 사용되지 않은 페이지 교체
4. **LFU** - Least ***Frequently*** Used : 참조 횟수가 가장 작은 페이지 교체
5. **MFU** - Most Frequently used : 참조 횟수가 가장 많은 페이지 교체
6. **NUR** - Not Used Recently : 최근에 사용하지 않은 페이지 교체

### OPT (Optimal Page Replacement) - 최적 페이지 교체

OPT 알고리즘은 앞으로 가장 사용하지 않을 페이지를 가장 우선적으로 내려 보내는 알고리즘이다. FIFO에 비해서 페이지 결함이 일어날 횟수가 더 적다. 하지만 OPT의 경우 앞으로도 사용이 잘 되지 않을 것이라는 보장이 없으므로 미래를 알 수 없기 때문에 실질적으로 수행하기에는 큰 어려움이 있다고 할 수 있다.

### FIFO (First-in First Out)

메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘이다. 따라서 victim page의 대상은 가장 먼저 메모리에 올라온 페이지가 되는 것이다.

이 방법은 가장 간단한 방법이다. 특히 초기화 코드에 대해서 적절한 방법이라고 할 수 있다. 초기화 코드는 처음에 프로세스가 실행될 때 최초 초기화를 시키는 역할만 진행하고 다른 역할은 수행하지 않기 때문에 메인 메모리에서 내려 보내도 괜찮다. 

하지만 처음에 프로세스를 실행시키는 데에 무조건 필요하다. 따라서 FIFO의 방법을 사용하면 초기화 시켜준 후 가장 먼저 내려 보내지게 된다. FIFO 알고리즘은 프레임의 수가 적을수록 페이지 결함이 더 많이 일어나게 된다. 계속 교체를 해주어야 하기 때문이다. 하지만 프레임의 수가 많아질수록 페이지 결함의 횟수는 감소하게 된다.

**Belady's Anomaly 이란?**

- 간단히 말해서 페이지 교체 알고리즘 중의 하나인 FIFO(First In First Out)에서, 원래 페이지 프레임의 개수를 늘리면 페이지 폴트 발생이 감소 해야 하나, 오히려 늘어나는 경우가 발생하는데 그것을 Belady's Anomaly라 한다.

### LRU (Least-Recently-Used)


LRU 알고리즘은 최근에 사용하지 않은 페이지를 가장 먼저 내려 보내는 알고리즘이다. 최근에 사용되지 않으면 나중에도 사용되지 않을 것이라는 아이디어로부터 온 것이다. 

OPT의 경우에는 미래에 대한 예측이지만 LRU의 경우에는 과거를 보고 판단하므로 실질적으로 사용 가능한 알고리즘이라고 할 수 있다. 실제로도 최근에 사용하지 않은 페이지는 앞으로도 사용하지 않을 확률이 높다고 할 수 있다.

비록 OPT보다는 페이지 결함이 더 일어날 수 있지만 실제로 사용할 수 있는 알고리즘 중에서는 좋은 방법 중 하나라고 할 수 있다.

### 여러 개의 프로세스들에 제한된 가용 메모리를 어떻게 할당할 것인가?

**균등 할당(equal allocation):** 100개의 프레임이 있으면 2개의 프로세스에 50개씩 할당해준다.

**비례 할당(proportional allocation):**  프로세스1이 프로세스2보다 메모리 사용량이 많으면 프로세스1에는 프레임을 80개 프로세스2에는 20개를 할당해준다. 

### 페이지를 교체하는 방식인 전역 교체, 지역 교체에 대해 설명해 주세요.

페이지를 **교**체하는 방식에는 전역 교체와 지역 교체로 두 가지의 방식이 존재한다. 

전역 교체는 메모리상의 모든 프로세스 페이지에 대해 교체를 하는 방식이고, 

지역 교체는 메모리상의 자기 프로세스 페이지에서만 교체를 하는 방식이다. 

다중 프로그래밍의 경우 메인 메모리에 다양한 프로세스가 동시에 올라올 수 있는데 따라서 다양한 프로세스의 페이지가 메모리에 존재하게 된다. 

페이지를 교체할 때 앞의 다양한 알고리즘에 의해 희생될 페이지를 선정하게 되는데 선정하는 기준이 전체를 기준으로 하느냐 자기 프로세스의 페이지를 기준으로 하느냐에 대한 차이다. 

실제로 전체를 기준으로 페이지를 교체하는 전역 교체가 더 효율적이라고 할 수 있다. 

하지만 전역 교체의 경우 한 가지 문제점이 있다. 프로세스의 메모리에 있는 페이지 집합이 해당 프로세스의 페이징 동작뿐만 아니라 다른 프로세스의 페이징 동작에도 영향을 받는다. 예를 들면, 어떨 때는 0.5초 걸리던 것이 다음 실행 때는 10초가 걸리 수 도 있다. 지역 교체 방법에서는 이런 현상이 발생하지 않는다.

### **스레싱(Thrashing)**

충분한 프레임이 없는경우, 또는 다른 이유로 반복적으로 페이지 폴트가 발생해서, 과도하게 페이지 교체 작업이 일어나, 실제로는 아무일도 하지 못하는 상황


## 조예은
